<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Mbrins462.GitHub.io/Projects : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Mbrins462.GitHub.io/Projects</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/mbrins462">View on GitHub</a>

          <h1 id="project_title">Welcome to My GitHub Pages!</h1>
          <h2 id="project_tagline"><font size="6"><a href="https://mbrins462.github.io" style="color:#CC6600">Home</a>&nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://mbrins462.github.io/Research" style="color:#990066">Research</a></font>&nbsp&nbsp&nbsp&nbsp&nbsp<font size="9"><a href="https://mbrins462.github.io/Projects" style="color:#3366FF">Projects</a></font></h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

<h3>
<a id="Data Incubator" class="anchor" href="#Projects" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Projects</h3>

<center><object width="500" height="400" data="images/data_inc_plot1.png"></object>
</center>  
<center><object width="500" height="400" data="images/data_inc_plot2.png"></object> 
</center>
<p>As I mentioned in my Home page, in addition to my research in physics I'm also interested in data science. I'll use this page to post information on <a href="https://www.kaggle.com">Kaggle</a> competitions for which I've submitted results, my code for these challenges (I invite you to look at <a href="https://github.com/mbrins462/Kaggle">my Kaggle repository</a>), and any other data science/machine learning related projects that I am working on. At the bottom of this page I've included a table with my scores for the different competitions.</p>

<h3>
<a id="Kaggle Competitions" class="anchor" href="#Kaggle Competitions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Kaggle Competitions</h3>
<p><strong>Titanic Passenger Survival</strong></br>
The goal of the Titanic passenger survival competition is to use the provided training set that includes passengers on the Titanic as well as their personal information and some other details about their voyage including whether or not they survived, and build a model that predicts the survival of other passengers.
</p>
<p>Scores for the Titanic challenge are based on a model's accuracy. For the challenge, we have a binary classification problem. Either the passenger survives, or doesn't. We can just assign a 0 or a 1 to these cases.There are four possible outcomes for a single prediction:
<ul>
    <li>True Positive  --> guess survived, passenger survived</li>
    <li>True Negative  --> guess deceased, passenger died</li>
    <li>False Positive --> guess survived, passenger died</li>
    <li>False Negative --> guess deceased, passenger survived</li>
</ul>
Accuracy is just the number of times the model guesses correctly divided by the total number of guesses.
<center><a href="https://www.codecogs.com/eqnedit.php?latex=Accuracy&space;=&space;\frac{TP&space;&plus;&space;TN}{TP&space;&plus;&space;TN&space;&plus;&space;FP&space;&plus;&space;FN}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Accuracy&space;=&space;\frac{TP&space;&plus;&space;TN}{TP&space;&plus;&space;TN&space;&plus;&space;FP&space;&plus;&space;FN}" title="Accuracy = \frac{TP + TN}{TP + TN + FP + FN}" /></a>.
</center>
I used python's sklearn random forest classifier for my model. Random forests are built up by multiple decision trees, which look at the training data set and decide how to split the variables given in order to make a classification. Trees are very good for data sets with variables of different scales as well as features that turn out to be unimportant, but are prone to inaccuracies. Random forests use the multiple trees to find an aggregated model that has less variance. The nature of this challenge lends itself well to using a random forest classifier.
</p>

<p><strong>Digit Recognizer</strong></br>
In the digit recognizer challenge, Kaggle provides a set of hand written digits and the goal is to build a machine learning model that can learn to correctly identify other hand written digits. The score for this challenge is based on the percentage of correct classifications. This is a similar metric to the accuracy described in the Titanic section, except that there are 10 possible classifications rather than binary classification.
</p>
<p>I used the sklearn k-Neighbors classifier for this challenge using the 20 nearest neighbors weighted by their Euclidean distance. My k-Neighbors classifier uses the <i>k</i> = 20 nearest neighbors, determined by their Euclidean distance to the digit that is to be recognized. The Euclidean distance between the test point <i>X</i> and a training point<i>x</i> is 
<center><a href="https://www.codecogs.com/eqnedit.php?latex=d&space;=&space;\sum_{i&space;=&space;1}^N\sqrt{(X_i&space;-&space;x_i)^2)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?d&space;=&space;\sum_{i&space;=&space;1}^N\sqrt{(X_i&space;-&space;x_i)^2)}" title="d = \sum_{i = 1}^N\sqrt{(X_i - x_i)^2)}" /></a>
</center>
where <i>N</i> = 784 (each image is 28x28 pixels). The classifier then weights each of the 20 neighbors by <i>1/d</i> and assigns a class to the test point based on the weighted values of the neighbors.
</p>

<p><strong>San Francisco Crime Classification</strong></br>
In this competition, Kaggle provides a data set of crime in San Francisco with times, locations, types of crime, and a few other features. The target variable for the test set is the type of crime. The goal is to predict based on features of the test set what the probability that a crime is of a certain type of crime. The competition was evaluated by the log loss function
<center><a href="https://www.codecogs.com/eqnedit.php?latex=log\,loss&space;=&space;-\frac{1}{N}\sum_{i&space;=&space;1}^{N}\sum_{j=1}^{M}\,y_{ij}\ln(p_{ij})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?log\,loss&space;=&space;-\frac{1}{N}\sum_{i&space;=&space;1}^{N}\sum_{j=1}^{M}\,y_{ij}\ln(p_{ij})" title="log\,loss = -\frac{1}{N}\sum_{i = 1}^{N}\sum_{j=1}^{M}\,y_{ij}\ln(p_{ij})" /></a>
</center>
since from the Kaggle website, "this error metric is used where contestants have to predict that something is true or false with a probability (likelihood) ranging from definitely true (1) to equally true (0.5) to definitely false(0)."
</p>

<p><strong>Santander Customer Satisfaction</strong></br>

</p>
<p>

<table style="width:100%">
    <tr>
        <th>Challenge</th>
        <th>Score</th>
        <th>Additional Info</th>
    </tr>
    <tr>
        <td>Santander Customer</br>Satisfaction</td>
        <td>0.825421</br>Ranked 1654/5123</br>(high score 0.829072)</br>(top %33)</td>
        <td>Score determined by area under ROC</br>curve. Competition closed</br>May 2, 2016.</td>
    <tr>
    <tr>
        <td>San Francisco Crime</br>Classification</td>
        <td>4.24398</br>Ranked 1757/2335</br>(top 75%)</td>
        <td>Score determined by multi-class</br>logarithmic loss. Competition closed</br>June 6, 2016.</td>
    <tr>
        <td>Digit Recognizer</td>
        <td>0.96029</td>
        <td>Score determined by percent accuracy</br>of digit recognition.</td>
    <tr>
        <td>Titanic</td>
        <td>0.78469</td>
        <td>Score determined by percent accuracy</br>of passenger survival prediction.</td>
    </tr>

</table>
</p>
      </section>
        </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
